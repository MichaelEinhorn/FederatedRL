{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import gym\n",
    "import gym3\n",
    "from procgen import ProcgenGym3Env\n",
    "from torchinfo import summary\n",
    "import time\n",
    "\n",
    "import resnet\n",
    "import datastructures\n",
    "import core\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict(rgb=D256[64,64,3])\n",
      "D15[]\n"
     ]
    }
   ],
   "source": [
    "num_agents = 16\n",
    "env = ProcgenGym3Env(num=num_agents, env_name=\"coinrun\", distribution_mode=\"easy\", paint_vel_info=True)\n",
    "print(env.ob_space)\n",
    "print(env.ac_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNNAgent                                 [2, 15]                   --\n",
       "├─Conv2d: 1-1                            [2, 16, 64, 64]           432\n",
       "├─MaxPool2d: 1-2                         [2, 16, 32, 32]           --\n",
       "├─Sequential: 1-3                        [2, 16, 32, 32]           --\n",
       "│    └─BasicBlock: 2-1                   [2, 16, 32, 32]           --\n",
       "│    │    └─BatchNorm2d: 3-1             [2, 16, 32, 32]           32\n",
       "│    │    └─ReLU: 3-2                    [2, 16, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-3                  [2, 16, 32, 32]           2,304\n",
       "│    │    └─BatchNorm2d: 3-4             [2, 16, 32, 32]           32\n",
       "│    │    └─ReLU: 3-5                    [2, 16, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-6                  [2, 16, 32, 32]           2,304\n",
       "├─Sequential: 1-4                        [2, 16, 16, 16]           --\n",
       "│    └─BasicBlock: 2-2                   [2, 16, 16, 16]           --\n",
       "│    │    └─BatchNorm2d: 3-7             [2, 16, 32, 32]           32\n",
       "│    │    └─ReLU: 3-8                    [2, 16, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-9                  [2, 16, 16, 16]           2,304\n",
       "│    │    └─BatchNorm2d: 3-10            [2, 16, 16, 16]           32\n",
       "│    │    └─ReLU: 3-11                   [2, 16, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-12                 [2, 16, 16, 16]           2,304\n",
       "│    │    └─Sequential: 3-13             [2, 16, 16, 16]           288\n",
       "├─Sequential: 1-5                        [2, 16, 8, 8]             --\n",
       "│    └─BasicBlock: 2-3                   [2, 16, 8, 8]             --\n",
       "│    │    └─BatchNorm2d: 3-14            [2, 16, 16, 16]           32\n",
       "│    │    └─ReLU: 3-15                   [2, 16, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-16                 [2, 16, 8, 8]             2,304\n",
       "│    │    └─BatchNorm2d: 3-17            [2, 16, 8, 8]             32\n",
       "│    │    └─ReLU: 3-18                   [2, 16, 8, 8]             --\n",
       "│    │    └─Conv2d: 3-19                 [2, 16, 8, 8]             2,304\n",
       "│    │    └─Sequential: 3-20             [2, 16, 8, 8]             288\n",
       "├─Sequential: 1-6                        [2, 16, 4, 4]             --\n",
       "│    └─BasicBlock: 2-4                   [2, 16, 4, 4]             --\n",
       "│    │    └─BatchNorm2d: 3-21            [2, 16, 8, 8]             32\n",
       "│    │    └─ReLU: 3-22                   [2, 16, 8, 8]             --\n",
       "│    │    └─Conv2d: 3-23                 [2, 16, 4, 4]             2,304\n",
       "│    │    └─BatchNorm2d: 3-24            [2, 16, 4, 4]             32\n",
       "│    │    └─ReLU: 3-25                   [2, 16, 4, 4]             --\n",
       "│    │    └─Conv2d: 3-26                 [2, 16, 4, 4]             2,304\n",
       "│    │    └─Sequential: 3-27             [2, 16, 4, 4]             288\n",
       "├─Flatten: 1-7                           [2, 256]                  --\n",
       "├─Linear: 1-8                            [2, 15]                   3,855\n",
       "├─ValueHead: 1-9                         [2, 1]                    --\n",
       "│    └─Linear: 2-5                       [2, 1]                    257\n",
       "==========================================================================================\n",
       "Total params: 24,096\n",
       "Trainable params: 24,096\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 16.25\n",
       "==========================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 2.87\n",
       "Params size (MB): 0.10\n",
       "Estimated Total Size (MB): 3.07\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from CVModels import CNNAgent\n",
    "from PPO import PPO\n",
    "\n",
    "model = CNNAgent([64, 64, 3], 15, channels=16, layers=[1,1,1,1], scale=[1,1,1,1], vheadLayers=1).to(device)\n",
    "model.train()\n",
    "ppo = PPO(model, env, num_agents=num_agents)\n",
    "\n",
    "summary(model, input_size=(2, 3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppo.runGame()\n",
    "# loss = ppo.train(debug=True)\n",
    "# print(loss)\n",
    "# import torchviz\n",
    "# torchviz.make_dot(loss, params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episodeLength 138.875 nonZeroReward 0.625 epoch 0 steps 4096 loss 0.11894977919804514 policy 0.07235269021885041 value 0.04659708897919471 entropy 2.4408762454986572\n",
      "time/runGame 2.5554771423339844\n",
      "time/computeAdvantages 0.05899333953857422\n",
      "time/ppo/forward 1.3123829364776611\n",
      "time/ppo/backward 2.054478406906128\n",
      "time/ppo/optim 2.178558588027954\n",
      "time/ppo/stats 0.7469000816345215\n",
      "time/epoch 6.9931254386901855\n",
      "time/game/observe 0.2519690990447998\n",
      "time/game/act 0.021007537841796875\n",
      "time/game/forward 1.8530879020690918\n",
      "time/game/stats 0.18725156784057617\n",
      "time/game/transition 0.15802001953125\n",
      "episodeLength 424.85714285714283 nonZeroReward 0.7142857142857143 epoch 10 steps 45056 loss 0.014673157579111163 policy 0.012471733978299527 value 0.0022014236008116423 entropy 2.1042418479919434\n",
      "episodeLength 133.23333333333332 nonZeroReward 0.5333333333333333 epoch 20 steps 86016 loss 0.010302181355397518 policy 0.005014551941518333 value 0.005287629413879178 entropy 2.0411903858184814\n",
      "episodeLength 101.74418604651163 nonZeroReward 0.5581395348837209 epoch 30 steps 126976 loss 0.01751119305972937 policy 0.00954707349448971 value 0.007964119565239647 entropy 2.022834062576294\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Michael Einhorn\\Documents\\GTML\\RL\\procgen.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/GTML/RL/procgen.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/GTML/RL/procgen.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     ppo\u001b[39m.\u001b[39mrunGame()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/GTML/RL/procgen.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     ppo\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/GTML/RL/procgen.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/GTML/RL/procgen.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mepisodeLength\u001b[39m\u001b[39m\"\u001b[39m, ppo\u001b[39m.\u001b[39mall_stats[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mepisodeLength\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mnonZeroReward\u001b[39m\u001b[39m\"\u001b[39m, ppo\u001b[39m.\u001b[39mall_stats[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mnonZeroReward\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/GTML/RL/procgen.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m, ppo\u001b[39m.\u001b[39mall_stats[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39msteps\u001b[39m\u001b[39m\"\u001b[39m, ppo\u001b[39m.\u001b[39mall_stats[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39msteps\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/GTML/RL/procgen.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m, ppo\u001b[39m.\u001b[39mall_stats[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mppo/loss/total\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitem(), \u001b[39m\"\u001b[39m\u001b[39mpolicy\u001b[39m\u001b[39m\"\u001b[39m, ppo\u001b[39m.\u001b[39mall_stats[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mppo/loss/policy\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitem(), \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/GTML/RL/procgen.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, ppo\u001b[39m.\u001b[39mall_stats[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mppo/loss/value\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitem(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Michael%20Einhorn/Documents/GTML/RL/procgen.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39mentropy\u001b[39m\u001b[39m\"\u001b[39m, ppo\u001b[39m.\u001b[39mall_stats[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mppo/policy/entropy\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\Michael Einhorn\\Documents\\GTML\\RL\\PPO.py:126\u001b[0m, in \u001b[0;36mPPO.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtiming[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtime/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malg_name\u001b[39m}\u001b[39;00m\u001b[39m/backward\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t\n\u001b[0;32m    125\u001b[0m t \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 126\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtiming[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtime/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malg_name\u001b[39m}\u001b[39;00m\u001b[39m/optim\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t\n\u001b[0;32m    129\u001b[0m t \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\optim\\optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    108\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 109\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\optim\\adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    155\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 157\u001b[0m     adam(params_with_grad,\n\u001b[0;32m    158\u001b[0m          grads,\n\u001b[0;32m    159\u001b[0m          exp_avgs,\n\u001b[0;32m    160\u001b[0m          exp_avg_sqs,\n\u001b[0;32m    161\u001b[0m          max_exp_avg_sqs,\n\u001b[0;32m    162\u001b[0m          state_steps,\n\u001b[0;32m    163\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    164\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    165\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    166\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    167\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    168\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    169\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    170\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    171\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    173\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\optim\\adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 213\u001b[0m func(params,\n\u001b[0;32m    214\u001b[0m      grads,\n\u001b[0;32m    215\u001b[0m      exp_avgs,\n\u001b[0;32m    216\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    217\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    218\u001b[0m      state_steps,\n\u001b[0;32m    219\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    220\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    221\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    222\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    223\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    224\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    225\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    226\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\optim\\adam.py:307\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[0;32m    305\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    306\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39;49madd_(eps)\n\u001b[0;32m    309\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    ppo.runGame()\n",
    "    ppo.train()\n",
    "    if i % 10 == 0:\n",
    "        print(\"episodeLength\", ppo.all_stats[-1][\"episodeLength\"], \"nonZeroReward\", ppo.all_stats[-1][\"nonZeroReward\"],\n",
    "              \"epoch\", ppo.all_stats[-1][\"epoch\"], \"steps\", ppo.all_stats[-1][\"steps\"], \n",
    "              \"loss\", ppo.all_stats[-1][\"ppo/loss/total\"].item(), \"policy\", ppo.all_stats[-1][\"ppo/loss/policy\"].item(), \n",
    "              \"value\", ppo.all_stats[-1][\"ppo/loss/value\"].item(),\n",
    "              \"entropy\", ppo.all_stats[-1][\"ppo/policy/entropy\"].item())\n",
    "    if i % 100 == 0:\n",
    "        stats = ppo.all_stats[-1]\n",
    "        for k, v in stats.items():\n",
    "            if \"time\" in k:\n",
    "                print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ViTValue                                 [2, 15]                   --\n",
       "├─VisionTransformer: 1-1                 --                        1,152\n",
       "│    └─PatchEmbed: 2-1                   [2, 16, 64]               --\n",
       "│    │    └─Conv2d: 3-1                  [2, 64, 4, 4]             49,216\n",
       "│    │    └─Identity: 3-2                [2, 16, 64]               --\n",
       "│    └─Dropout: 2-2                      [2, 17, 64]               --\n",
       "│    └─Identity: 2-3                     [2, 17, 64]               --\n",
       "│    └─Sequential: 2-4                   [2, 17, 64]               --\n",
       "│    │    └─Block: 3-3                   [2, 17, 64]               33,472\n",
       "│    │    └─Block: 3-4                   [2, 17, 64]               33,472\n",
       "│    │    └─Block: 3-5                   [2, 17, 64]               33,472\n",
       "│    └─LayerNorm: 2-5                    [2, 17, 64]               128\n",
       "│    └─Identity: 2-6                     [2, 64]                   --\n",
       "│    └─Linear: 2-7                       [2, 15]                   975\n",
       "├─ValueHead: 1-2                         [2, 1]                    --\n",
       "│    └─Linear: 2-8                       [2, 1]                    65\n",
       "==========================================================================================\n",
       "Total params: 151,952\n",
       "Trainable params: 151,952\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 1.78\n",
       "==========================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 0.50\n",
       "Params size (MB): 0.60\n",
       "Estimated Total Size (MB): 1.21\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timm.models.vision_transformer import VisionTransformer\n",
    "h = 64\n",
    "dim = 64\n",
    "# model = VisionTransformer(img_size=h, num_classes=15, depth=3, num_heads=4, embed_dim=dim, mlp_ratio=2).to(device)\n",
    "\n",
    "\n",
    "class ViTValue(nn.Module):\n",
    "    def __init__(self, img_size=64, num_classes=15, depth=3, num_heads=4, embed_dim=64, mlp_ratio=2, valueHeadLayers=2):\n",
    "        super().__init__()\n",
    "        from CVModels import ValueHead\n",
    "        self.model = VisionTransformer(img_size=img_size, num_classes=num_classes, depth=depth, num_heads=num_heads, embed_dim=embed_dim, mlp_ratio=mlp_ratio)\n",
    "        self.value = ValueHead(n_in=model.embed_dim, n_out=1, layers=valueHeadLayers)\n",
    "    def forward(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        x = self.model.forward_head(x, True) # pre logits doesn't apply head layer yet\n",
    "        l = self.model.head(x)\n",
    "        v = self.value(x)\n",
    "        return l, v\n",
    "    \n",
    "model = ViTValue().to(device)\n",
    "summary(model, input_size=(2, 3, h, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac488eaa353570522d4c04bd2cd8e3c67c3437ec54aafb89a01cbc7941828458"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
